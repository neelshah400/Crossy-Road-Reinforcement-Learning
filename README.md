# Crossy Road Reinforcement Learning

| Name          | Email                     |
| :-----------: | :-----------------------: |
| Neel Shah     | neelshah@terpmail.umd.edu |
| Anish Bagri   | aabagri@terpmail.umd.edu  |
| Nathan Sankar | nsankar@terpmail.umd.edu  |
| Akul Gokaram  | agokaram@terpmail.umd.edu |
| Aditya Sharda | asharda@terpmail.umd.edu  |

# Setup

0. Ensure that [Python](https://www.python.org/) and [uv](https://github.com/astral-sh/uv) are set up on your machine.

1. Clone this repository.

   ```shell
   gh repo clone neelshah400/Crossy-Road-Reinforcement-Learning
   ```

2. Create a virtual environment.

   ```shell
   make create-venv
   ```

3. Activate the virtual environment.

   ```shell
   source .venv/bin/activate
   ```

4. Sync the virtual environment with the development dependencies.

   ```shell
   make sync-dev
   ```
